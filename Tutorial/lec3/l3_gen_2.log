Realizing Pipeline for target(arch_unknown-0-os_unknown)
jit-compiling for: target(x86-64-linux-avx-avx2-f16c-fma-jit-sse41)
Inferred argument: (void *) __user_context
Creating initial loop nests...
Injecting realization of { gradient }
for (.__root, 0, 1) {
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  let gradient.s0.__outermost.loop_extent = 1
  let gradient.s0.__outermost.loop_max = 0
  let gradient.s0.__outermost.loop_min = 0
  for (gradient.s0.__outermost, gradient.s0.__outermost.loop_min, gradient.s0.__outermost.loop_extent) {
   for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
    for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
     gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
    }
   }
  }
 }
}

Lowering after creating initial loop nests:
produce gradient {
 let gradient.s0.y.loop_max = gradient.s0.y.max
 let gradient.s0.y.loop_min = gradient.s0.y.min
 let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
 let gradient.s0.x.loop_max = gradient.s0.x.max
 let gradient.s0.x.loop_min = gradient.s0.x.min
 let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
 for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
  for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
   gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
  }
 }
}

Skipping injecting memoization...
Injecting tracing...
Lowering after injecting tracing:
produce gradient {
 let gradient.s0.y.loop_max = gradient.s0.y.max
 let gradient.s0.y.loop_min = gradient.s0.y.min
 let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
 let gradient.s0.x.loop_max = gradient.s0.x.max
 let gradient.s0.x.loop_min = gradient.s0.x.min
 let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
 for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
  for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
   gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
  }
 }
}

Adding checks for parameters
Lowering after injecting parameter checks:
produce gradient {
 let gradient.s0.y.loop_max = gradient.s0.y.max
 let gradient.s0.y.loop_min = gradient.s0.y.min
 let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
 let gradient.s0.x.loop_max = gradient.s0.x.max
 let gradient.s0.x.loop_min = gradient.s0.x.min
 let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
 for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
  for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
   gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
  }
 }
}

Computing bounds of each function's value
Bounds on value 0 for func gradient are: ((void *))neg_inf, ((void *))pos_inf
Adding checks for images
Injecting constraints for gradient.0
Injecting constraints for gradient.1
Lowering after injecting image checks:
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Performing computation bounds inference...
Lowering after computation bounds inference:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Removing extern loops...
Lowering after removing extern loops:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Performing sliding window optimization...
Lowering after sliding window:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Simplifying correlated differences...
Lowering after simplifying correlated differences:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Performing allocation bounds inference...
Lowering after allocation bounds inference:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Removing code that depends on undef values...
Lowering after removing code that depends on undef values:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Uniquifying variable names...
Lowering after uniquifying variable names:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Simplifying...
Lowering after first simplification:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Performing storage folding optimization...
Lowering after storage folding:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Injecting debug_to_file calls...
Lowering after injecting debug_to_file calls:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Injecting prefetches...
Lowering after injecting prefetches:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Discarding safe promises...
Lowering after discarding safe promises:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Dynamically skipping stages...
Lowering after dynamically skipping stages:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Forking asynchronous producers...
Lowering after forking asynchronous producers:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Destructuring tuple-valued realizations...
Lowering after destructuring tuple-valued realizations:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Performing storage flattening...
Lowering after storage flattening:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((0 + (gradient.s0.x*gradient.stride.0)) + (gradient.s0.y*gradient.stride.1)) - ((0 + (gradient.min.0*gradient.stride.0)) + (gradient.min.1*gradient.stride.1)))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Adding atomic mutex allocation...
Lowering after adding atomic mutex allocation:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((0 + (gradient.s0.x*gradient.stride.0)) + (gradient.s0.y*gradient.stride.1)) - ((0 + (gradient.min.0*gradient.stride.0)) + (gradient.min.1*gradient.stride.1)))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Unpacking buffer arguments...
Lowering after unpacking buffer arguments...
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((0 + (gradient.s0.x*gradient.stride.0)) + (gradient.s0.y*gradient.stride.1)) - ((0 + (gradient.min.0*gradient.stride.0)) + (gradient.min.1*gradient.stride.1)))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Skipping rewriting memoized allocations...
Simplifying...
Lowering after second simplifcation:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Reduce prefetch dimension...
Lowering after reduce prefetch dimension:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Simplifying correlated differences...
Lowering after simplifying correlated differences:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Unrolling...
Lowering after unrolling:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Vectorizing...
Lowering after vectorizing:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Detecting vector interleavings...
Lowering after rewriting vector interleavings:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Partitioning loops to simplify boundary conditions...
Lowering after partitioning loops:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Trimming loops to the region over which they do something...
Lowering after loop trimming:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Injecting early frees...
Lowering after injecting early frees:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Simplifying correlated differences...
Lowering after simplifying correlated differences:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Bounding small allocations...
Lowering after bounding small allocations:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Simplifying...
Lowering unsafe promises...
Lowering after lowering unsafe promises:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Lowering after final simplification:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let t1 = ((gradient.min.1*gradient.stride.1) + gradient.min.0)
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   let t2 = ((gradient.s0.y*gradient.stride.1) - t1)
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(gradient.s0.x + t2)] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Skipping Hexagon offload...
Target triple of initial module: x86_64--linux-gnu
Generating llvm bitcode...
Generating llvm bitcode prolog for function gradient...
Generating llvm bitcode for function gradient...
0x1c6c6c0
Done generating llvm bitcode
; ModuleID = 'gradient'
source_filename = "/home/dongkesi/github/Halide/src/runtime/halide_buffer_t.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64--linux-gnu"

%struct.halide_filter_argument_t = type { i8*, i32, i32, %struct.halide_type_t, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, %struct.halide_scalar_value_t*, i64** }
%struct.halide_type_t = type { i8, i8, i16 }
%struct.halide_scalar_value_t = type { %union.anon }
%union.anon = type { double }
%struct.halide_filter_metadata_t = type { i32, i32, %struct.halide_filter_argument_t*, i8*, i8* }
%struct.halide_buffer_t = type { i64, %struct.halide_device_interface_t*, i8*, i64, %struct.halide_type_t, i32, %struct.halide_dimension_t*, i8* }
%struct.halide_device_interface_t = type { i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, void (i8*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_device_interface_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i32, i32, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, %struct.halide_buffer_t*, i64, %struct.halide_device_interface_t*)*, i32 (i8*, %struct.halide_buffer_t*)*, i32 (i8*, i32*, i32*)*, %struct.halide_device_interface_impl_t* }
%struct.halide_device_interface_impl_t = type opaque
%struct.halide_dimension_t = type { i32, i32, i32, i32 }

@str = private constant [9 x i8] c"gradient\00", align 32
@str.3 = private constant [23 x i8] c"Output buffer gradient\00", align 32
@str.4 = private constant [18 x i8] c"gradient.stride.0\00", align 32
@str.5 = private constant [2 x i8] c"1\00", align 32
@str.6 = private constant [15 x i8] c"__user_context\00", align 32
@0 = private constant [4 x i64*] zeroinitializer
@1 = private constant [2 x %struct.halide_filter_argument_t] [%struct.halide_filter_argument_t { i8* getelementptr inbounds ([15 x i8], [15 x i8]* @str.6, i32 0, i32 0), i32 0, i32 0, %struct.halide_type_t { i8 3, i8 64, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** null }, %struct.halide_filter_argument_t { i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str, i32 0, i32 0), i32 2, i32 2, %struct.halide_type_t { i8 0, i8 32, i16 1 }, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, %struct.halide_scalar_value_t* null, i64** getelementptr inbounds ([4 x i64*], [4 x i64*]* @0, i32 0, i32 0) }]
@str.7 = private constant [54 x i8] c"x86-64-linux-avx-avx2-f16c-fma-jit-sse41-user_context\00", align 32
@gradient_metadata_storage = private constant %struct.halide_filter_metadata_t { i32 1, i32 2, %struct.halide_filter_argument_t* getelementptr inbounds ([2 x %struct.halide_filter_argument_t], [2 x %struct.halide_filter_argument_t]* @1, i32 0, i32 0), i8* getelementptr inbounds ([54 x i8], [54 x i8]* @str.7, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str, i32 0, i32 0) }

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #0

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nofree nounwind
declare i8* @memcpy(i8* returned, i8* nocapture readonly, i64) local_unnamed_addr #1

declare i32 @halide_error_bad_dimensions(i8*, i8*, i32, i32) local_unnamed_addr #2

declare i32 @halide_error_bad_type(i8*, i8*, i32, i32) local_unnamed_addr #2

declare i32 @halide_error_buffer_allocation_too_large(i8*, i8*, i64, i64) local_unnamed_addr #2

declare i32 @halide_error_buffer_argument_is_null(i8*, i8*) local_unnamed_addr #2

declare i32 @halide_error_buffer_extents_negative(i8*, i8*, i32, i32) local_unnamed_addr #2

declare i32 @halide_error_buffer_extents_too_large(i8*, i8*, i64, i64) local_unnamed_addr #2

declare i32 @halide_error_constraint_violated(i8*, i8*, i32, i8*, i32) local_unnamed_addr #2

declare i32 @halide_error_device_dirty_with_no_device_support(i8*, i8*) local_unnamed_addr #2

declare i32 @halide_error_host_is_null(i8*, i8*) local_unnamed_addr #2

; Function Attrs: nounwind
define i32 @gradient(i8* %__user_context, %struct.halide_buffer_t* noalias %gradient.buffer) local_unnamed_addr #3 {
entry:
  %u.i.i = alloca i32, align 4
  %0 = alloca [8 x i32], align 4
  %1 = icmp eq %struct.halide_buffer_t* %gradient.buffer, null
  br i1 %1, label %"assert failed", label %"assert succeeded", !prof !8

"assert failed":                                  ; preds = %entry
  %2 = tail call i32 @halide_error_buffer_argument_is_null(i8* %__user_context, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str, i64 0, i64 0)) #5
  br label %destructor_block

"assert succeeded":                               ; preds = %entry
  %host.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 2
  %3 = load i8*, i8** %host.i, align 8, !tbaa !9
  %4 = bitcast i32* %u.i.i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %4) #5
  %5 = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 4, i32 0
  %call.i.i = call i8* @memcpy(i8* nonnull %4, i8* nonnull %5, i64 4) #7
  %6 = load i32, i32* %u.i.i, align 4, !tbaa !18
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %4) #5
  %flags.i.i.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 3
  %7 = load i64, i64* %flags.i.i.i, align 8, !tbaa !19
  %dimensions.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 5
  %8 = load i32, i32* %dimensions.i, align 4, !tbaa !20
  %dim.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 6
  %9 = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i, align 8, !tbaa !21
  %min.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 0, i32 0
  %10 = load i32, i32* %min.i, align 4, !tbaa !22
  %extent.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 0, i32 1
  %11 = load i32, i32* %extent.i, align 4, !tbaa !24
  %stride.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 0, i32 2
  %12 = load i32, i32* %stride.i, align 4, !tbaa !25
  %min.i17 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 1, i32 0
  %13 = load i32, i32* %min.i17, align 4, !tbaa !22
  %extent.i19 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 1, i32 1
  %14 = load i32, i32* %extent.i19, align 4, !tbaa !24
  %stride.i21 = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %9, i64 1, i32 2
  %15 = load i32, i32* %stride.i21, align 4, !tbaa !25
  %16 = load i8*, i8** %host.i, align 8, !tbaa !9
  %cmp.i = icmp eq i8* %16, null
  br i1 %cmp.i, label %_halide_buffer_is_bounds_query.exit, label %true_bb1

_halide_buffer_is_bounds_query.exit:              ; preds = %"assert succeeded"
  %device.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 0
  %17 = load i64, i64* %device.i, align 8, !tbaa !26
  %cmp1.i = icmp eq i64 %17, 0
  br i1 %cmp1.i, label %after_bb, label %true_bb1

destructor_block:                                 ; preds = %"end for gradient.s0.x", %_halide_buffer_is_bounds_query.exit31, %"produce gradient", %"assert failed"
  %18 = phi i32 [ %2, %"assert failed" ], [ 0, %_halide_buffer_is_bounds_query.exit31 ], [ 0, %"produce gradient" ], [ 0, %"end for gradient.s0.x" ]
  ret i32 %18

after_bb:                                         ; preds = %_halide_buffer_is_bounds_query.exit
  %19 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 0
  store i32 %10, i32* %19, align 4
  %20 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 1
  store i32 %11, i32* %20, align 4
  %21 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 2
  store i32 1, i32* %21, align 4
  %22 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 3
  store i32 0, i32* %22, align 4
  %23 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 4
  store i32 %13, i32* %23, align 4
  %24 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 5
  store i32 %14, i32* %24, align 4
  %25 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 6
  store i32 %11, i32* %25, align 4
  %26 = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 7
  store i32 0, i32* %26, align 4
  store i8 0, i8* %5, align 8, !tbaa !27
  %bits.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 4, i32 1
  %27 = bitcast %struct.halide_buffer_t* %gradient.buffer to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %27, i8 0, i64 24, i1 false)
  store i8 32, i8* %bits.i, align 1, !tbaa !28
  %lanes.i = getelementptr inbounds %struct.halide_buffer_t, %struct.halide_buffer_t* %gradient.buffer, i64 0, i32 4, i32 2
  store i16 1, i16* %lanes.i, align 2, !tbaa !29
  store i32 2, i32* %dimensions.i, align 4, !tbaa !20
  %28 = bitcast %struct.halide_dimension_t* %9 to i8*
  %29 = bitcast [8 x i32]* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %28, i8* nonnull align 4 %29, i64 16, i1 false) #5, !tbaa.struct !30
  %.pre.i = load %struct.halide_dimension_t*, %struct.halide_dimension_t** %dim.i, align 8, !tbaa !21
  %arrayidx.i = getelementptr inbounds [8 x i32], [8 x i32]* %0, i64 0, i64 4
  %arrayidx12.i = getelementptr inbounds %struct.halide_dimension_t, %struct.halide_dimension_t* %.pre.i, i64 1
  %30 = bitcast %struct.halide_dimension_t* %arrayidx12.i to i8*
  %31 = bitcast i32* %arrayidx.i to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %30, i8* nonnull align 4 %31, i64 16, i1 false) #5, !tbaa.struct !30
  store i64 0, i64* %flags.i.i.i, align 8, !tbaa !19
  %.pr.pre = load i8*, i8** %host.i, align 8, !tbaa !9
  %phitmp = icmp eq i8* %.pr.pre, null
  br i1 %phitmp, label %_halide_buffer_is_bounds_query.exit31, label %true_bb1

_halide_buffer_is_bounds_query.exit31:            ; preds = %after_bb
  %.pr = load i64, i64* %device.i, align 8, !tbaa !26
  %cmp1.i29 = icmp eq i64 %.pr, 0
  br i1 %cmp1.i29, label %destructor_block, label %true_bb1

true_bb1:                                         ; preds = %_halide_buffer_is_bounds_query.exit, %"assert succeeded", %after_bb, %_halide_buffer_is_bounds_query.exit31
  %32 = icmp ne i32 %6, 73728
  %33 = zext i1 %32 to i64
  %34 = icmp ne i32 %8, 2
  %35 = zext i1 %34 to i64
  %36 = shl nuw nsw i64 %35, 1
  %gradient.extent.0.lobit = lshr i32 %11, 31
  %37 = shl nuw nsw i32 %gradient.extent.0.lobit, 2
  %38 = zext i32 %37 to i64
  %gradient.extent.1.lobit = lshr i32 %14, 31
  %39 = shl nuw nsw i32 %gradient.extent.1.lobit, 3
  %40 = zext i32 %39 to i64
  %41 = icmp ne i32 %12, 1
  %42 = zext i1 %41 to i64
  %43 = shl nuw nsw i64 %42, 4
  %44 = or i64 %36, %33
  %45 = or i64 %44, %38
  %46 = or i64 %45, %43
  %47 = or i64 %46, %40
  %48 = or i64 %47, -9223372036854775808
  %49 = call i64 @llvm.cttz.i64(i64 %48, i1 true), !range !31
  %50 = trunc i64 %49 to i32
  switch i32 %50, label %no_errors_bb [
    i32 0, label %assert_failed
    i32 1, label %assert_failed4
    i32 2, label %assert_failed5
    i32 3, label %assert_failed6
    i32 4, label %assert_failed7
  ], !prof !32

no_errors_bb:                                     ; preds = %true_bb1
  %51 = sext i32 %14 to i64
  %52 = sext i32 %11 to i64
  %gradient.total_extent.1 = mul nsw i64 %51, %52
  %53 = icmp slt i32 %11, 0
  %54 = sub nsw i64 0, %52
  %55 = select i1 %53, i64 %54, i64 %52
  %56 = icmp ugt i64 %55, 2147483647
  %57 = zext i1 %56 to i64
  %58 = sext i32 %15 to i64
  %x2 = mul nsw i64 %58, %51
  %59 = icmp slt i64 %x2, 0
  %60 = sub nsw i64 0, %x2
  %61 = select i1 %59, i64 %60, i64 %x2
  %62 = icmp ugt i64 %61, 2147483647
  %63 = zext i1 %62 to i64
  %64 = shl nuw nsw i64 %63, 1
  %65 = icmp sgt i64 %gradient.total_extent.1, 2147483647
  %66 = zext i1 %65 to i64
  %67 = shl nuw nsw i64 %66, 2
  %68 = shl i64 %7, 2
  %69 = and i64 %68, 8
  %70 = icmp eq i8* %3, null
  %71 = zext i1 %70 to i64
  %72 = shl nuw nsw i64 %71, 4
  %73 = or i64 %72, %69
  %74 = or i64 %73, %57
  %75 = or i64 %74, %67
  %76 = or i64 %75, %64
  %77 = or i64 %76, -9223372036854775808
  %78 = call i64 @llvm.cttz.i64(i64 %77, i1 true), !range !31
  %79 = trunc i64 %78 to i32
  switch i32 %79, label %"produce gradient" [
    i32 0, label %assert_failed9
    i32 1, label %assert_failed10
    i32 2, label %assert_failed11
    i32 3, label %assert_failed12
    i32 4, label %assert_failed13
  ], !prof !32

assert_failed:                                    ; preds = %true_bb1
  %80 = call i32 @halide_error_bad_type(i8* %__user_context, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @str.3, i64 0, i64 0), i32 %6, i32 73728) #5
  ret i32 %80

assert_failed4:                                   ; preds = %true_bb1
  %81 = call i32 @halide_error_bad_dimensions(i8* %__user_context, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @str.3, i64 0, i64 0), i32 %8, i32 2) #5
  ret i32 %81

assert_failed5:                                   ; preds = %true_bb1
  %82 = call i32 @halide_error_buffer_extents_negative(i8* %__user_context, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @str.3, i64 0, i64 0), i32 0, i32 %11) #5
  ret i32 %82

assert_failed6:                                   ; preds = %true_bb1
  %83 = call i32 @halide_error_buffer_extents_negative(i8* %__user_context, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @str.3, i64 0, i64 0), i32 1, i32 %14) #5
  ret i32 %83

assert_failed7:                                   ; preds = %true_bb1
  %84 = call i32 @halide_error_constraint_violated(i8* %__user_context, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @str.4, i64 0, i64 0), i32 %12, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @str.5, i64 0, i64 0), i32 1) #5
  ret i32 %84

assert_failed9:                                   ; preds = %no_errors_bb
  %85 = call i32 @halide_error_buffer_allocation_too_large(i8* %__user_context, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str, i64 0, i64 0), i64 %55, i64 2147483647) #5
  ret i32 %85

assert_failed10:                                  ; preds = %no_errors_bb
  %86 = call i32 @halide_error_buffer_allocation_too_large(i8* %__user_context, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str, i64 0, i64 0), i64 %61, i64 2147483647) #5
  ret i32 %86

assert_failed11:                                  ; preds = %no_errors_bb
  %87 = call i32 @halide_error_buffer_extents_too_large(i8* %__user_context, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @str, i64 0, i64 0), i64 %gradient.total_extent.1, i64 2147483647) #5
  ret i32 %87

assert_failed12:                                  ; preds = %no_errors_bb
  %88 = call i32 @halide_error_device_dirty_with_no_device_support(i8* %__user_context, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @str.3, i64 0, i64 0)) #5
  ret i32 %88

assert_failed13:                                  ; preds = %no_errors_bb
  %89 = call i32 @halide_error_host_is_null(i8* %__user_context, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @str.3, i64 0, i64 0)) #5
  ret i32 %89

"produce gradient":                               ; preds = %no_errors_bb
  %90 = icmp sgt i32 %14, 0
  br i1 %90, label %"for gradient.s0.y.preheader", label %destructor_block, !prof !33

"for gradient.s0.y.preheader":                    ; preds = %"produce gradient"
  %91 = add nsw i32 %14, %13
  %92 = add nsw i32 %11, %10
  %93 = icmp sgt i32 %11, 0
  %94 = bitcast i8* %3 to i32*
  %95 = sext i32 %10 to i64
  %96 = sext i32 %13 to i64
  %sext36 = sext i32 %91 to i64
  %sext = sext i32 %92 to i64
  %97 = sub nsw i64 %sext, %95
  %98 = sub nsw i64 %sext, %95
  %99 = add nsw i64 %98, -8
  %100 = lshr i64 %99, 3
  %101 = add nuw nsw i64 %100, 1
  %min.iters.check = icmp ult i64 %97, 8
  %n.vec = and i64 %97, -8
  %ind.end = add nsw i64 %n.vec, %95
  %.splatinsert = insertelement <8 x i64> undef, i64 %95, i32 0
  %.splat = shufflevector <8 x i64> %.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %induction = add <8 x i64> %.splat, <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>
  %xtraiter = and i64 %101, 3
  %102 = icmp ult i64 %99, 24
  %unroll_iter = sub nsw i64 %101, %xtraiter
  %lcmp.mod = icmp eq i64 %xtraiter, 0
  %cmp.n = icmp eq i64 %97, %n.vec
  br label %"for gradient.s0.y"

"for gradient.s0.y":                              ; preds = %"for gradient.s0.y.preheader", %"end for gradient.s0.x"
  %indvars.iv34 = phi i64 [ %96, %"for gradient.s0.y.preheader" ], [ %indvars.iv.next35, %"end for gradient.s0.x" ]
  br i1 %93, label %"for gradient.s0.x.preheader", label %"end for gradient.s0.x", !prof !33

"for gradient.s0.x.preheader":                    ; preds = %"for gradient.s0.y"
  %103 = trunc i64 %indvars.iv34 to i32
  %reass.add = sub i32 %103, %13
  %reass.mul = mul i32 %reass.add, %15
  %t2 = sub i32 %reass.mul, %10
  %104 = sext i32 %t2 to i64
  br i1 %min.iters.check, label %"for gradient.s0.x.preheader40", label %vector.ph

vector.ph:                                        ; preds = %"for gradient.s0.x.preheader"
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %indvars.iv34, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  br i1 %102, label %middle.block.unr-lcssa, label %vector.body

vector.body:                                      ; preds = %vector.ph, %vector.body
  %index = phi i64 [ %index.next.3, %vector.body ], [ 0, %vector.ph ]
  %vec.ind = phi <8 x i64> [ %vec.ind.next.3, %vector.body ], [ %induction, %vector.ph ]
  %niter = phi i64 [ %niter.nsub.3, %vector.body ], [ %unroll_iter, %vector.ph ]
  %offset.idx = add i64 %index, %95
  %105 = add nsw <8 x i64> %vec.ind, %broadcast.splat
  %106 = add nsw i64 %offset.idx, %104
  %107 = getelementptr inbounds i32, i32* %94, i64 %106
  %108 = trunc <8 x i64> %105 to <8 x i32>
  %109 = bitcast i32* %107 to <8 x i32>*
  store <8 x i32> %108, <8 x i32>* %109, align 4, !tbaa !34
  %index.next = or i64 %index, 8
  %vec.ind.next = add <8 x i64> %vec.ind, <i64 8, i64 8, i64 8, i64 8, i64 8, i64 8, i64 8, i64 8>
  %offset.idx.1 = add i64 %index.next, %95
  %110 = add nsw <8 x i64> %vec.ind.next, %broadcast.splat
  %111 = add nsw i64 %offset.idx.1, %104
  %112 = getelementptr inbounds i32, i32* %94, i64 %111
  %113 = trunc <8 x i64> %110 to <8 x i32>
  %114 = bitcast i32* %112 to <8 x i32>*
  store <8 x i32> %113, <8 x i32>* %114, align 4, !tbaa !34
  %index.next.1 = or i64 %index, 16
  %vec.ind.next.1 = add <8 x i64> %vec.ind, <i64 16, i64 16, i64 16, i64 16, i64 16, i64 16, i64 16, i64 16>
  %offset.idx.2 = add i64 %index.next.1, %95
  %115 = add nsw <8 x i64> %vec.ind.next.1, %broadcast.splat
  %116 = add nsw i64 %offset.idx.2, %104
  %117 = getelementptr inbounds i32, i32* %94, i64 %116
  %118 = trunc <8 x i64> %115 to <8 x i32>
  %119 = bitcast i32* %117 to <8 x i32>*
  store <8 x i32> %118, <8 x i32>* %119, align 4, !tbaa !34
  %index.next.2 = or i64 %index, 24
  %vec.ind.next.2 = add <8 x i64> %vec.ind, <i64 24, i64 24, i64 24, i64 24, i64 24, i64 24, i64 24, i64 24>
  %offset.idx.3 = add i64 %index.next.2, %95
  %120 = add nsw <8 x i64> %vec.ind.next.2, %broadcast.splat
  %121 = add nsw i64 %offset.idx.3, %104
  %122 = getelementptr inbounds i32, i32* %94, i64 %121
  %123 = trunc <8 x i64> %120 to <8 x i32>
  %124 = bitcast i32* %122 to <8 x i32>*
  store <8 x i32> %123, <8 x i32>* %124, align 4, !tbaa !34
  %index.next.3 = add i64 %index, 32
  %vec.ind.next.3 = add <8 x i64> %vec.ind, <i64 32, i64 32, i64 32, i64 32, i64 32, i64 32, i64 32, i64 32>
  %niter.nsub.3 = add i64 %niter, -4
  %niter.ncmp.3 = icmp eq i64 %niter.nsub.3, 0
  br i1 %niter.ncmp.3, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !37

middle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph
  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.3, %vector.body ]
  %vec.ind.unr = phi <8 x i64> [ %induction, %vector.ph ], [ %vec.ind.next.3, %vector.body ]
  br i1 %lcmp.mod, label %middle.block, label %vector.body.epil

vector.body.epil:                                 ; preds = %middle.block.unr-lcssa, %vector.body.epil
  %index.epil = phi i64 [ %index.next.epil, %vector.body.epil ], [ %index.unr, %middle.block.unr-lcssa ]
  %vec.ind.epil = phi <8 x i64> [ %vec.ind.next.epil, %vector.body.epil ], [ %vec.ind.unr, %middle.block.unr-lcssa ]
  %epil.iter = phi i64 [ %epil.iter.sub, %vector.body.epil ], [ %xtraiter, %middle.block.unr-lcssa ]
  %offset.idx.epil = add i64 %index.epil, %95
  %125 = add nsw <8 x i64> %vec.ind.epil, %broadcast.splat
  %126 = add nsw i64 %offset.idx.epil, %104
  %127 = getelementptr inbounds i32, i32* %94, i64 %126
  %128 = trunc <8 x i64> %125 to <8 x i32>
  %129 = bitcast i32* %127 to <8 x i32>*
  store <8 x i32> %128, <8 x i32>* %129, align 4, !tbaa !34
  %index.next.epil = add i64 %index.epil, 8
  %vec.ind.next.epil = add <8 x i64> %vec.ind.epil, <i64 8, i64 8, i64 8, i64 8, i64 8, i64 8, i64 8, i64 8>
  %epil.iter.sub = add i64 %epil.iter, -1
  %epil.iter.cmp = icmp eq i64 %epil.iter.sub, 0
  br i1 %epil.iter.cmp, label %middle.block, label %vector.body.epil, !llvm.loop !39

middle.block:                                     ; preds = %vector.body.epil, %middle.block.unr-lcssa
  br i1 %cmp.n, label %"end for gradient.s0.x", label %"for gradient.s0.x.preheader40"

"for gradient.s0.x.preheader40":                  ; preds = %middle.block, %"for gradient.s0.x.preheader"
  %indvars.iv.ph = phi i64 [ %95, %"for gradient.s0.x.preheader" ], [ %ind.end, %middle.block ]
  br label %"for gradient.s0.x"

"for gradient.s0.x":                              ; preds = %"for gradient.s0.x.preheader40", %"for gradient.s0.x"
  %indvars.iv = phi i64 [ %indvars.iv.next, %"for gradient.s0.x" ], [ %indvars.iv.ph, %"for gradient.s0.x.preheader40" ]
  %130 = add nsw i64 %indvars.iv, %indvars.iv34
  %131 = add nsw i64 %indvars.iv, %104
  %132 = getelementptr inbounds i32, i32* %94, i64 %131
  %133 = trunc i64 %130 to i32
  store i32 %133, i32* %132, align 4, !tbaa !34
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %134 = icmp eq i64 %indvars.iv.next, %sext
  br i1 %134, label %"end for gradient.s0.x", label %"for gradient.s0.x", !llvm.loop !41

"end for gradient.s0.x":                          ; preds = %"for gradient.s0.x", %middle.block, %"for gradient.s0.y"
  %indvars.iv.next35 = add nsw i64 %indvars.iv34, 1
  %135 = icmp eq i64 %indvars.iv.next35, %sext36
  br i1 %135, label %destructor_block, label %"for gradient.s0.y"
}

; Function Attrs: nounwind readnone speculatable
declare i64 @llvm.cttz.i64(i64, i1 immarg) #4

; Function Attrs: nounwind
define i32 @gradient_argv(i8** nocapture readonly) local_unnamed_addr #5 {
entry:
  %1 = bitcast i8** %0 to i8***
  %2 = load i8**, i8*** %1, align 8
  %3 = load i8*, i8** %2, align 8
  %4 = getelementptr i8*, i8** %0, i64 1
  %5 = bitcast i8** %4 to %struct.halide_buffer_t**
  %6 = load %struct.halide_buffer_t*, %struct.halide_buffer_t** %5, align 8
  %7 = tail call i32 @gradient(i8* %3, %struct.halide_buffer_t* %6) #8
  ret i32 %7
}

; Function Attrs: norecurse nounwind readnone
define nonnull %struct.halide_filter_metadata_t* @gradient_metadata() local_unnamed_addr #6 {
entry:
  ret %struct.halide_filter_metadata_t* @gradient_metadata_storage
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #0

attributes #0 = { argmemonly nounwind }
attributes #1 = { nofree nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind "reciprocal-estimates"="none" }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { nounwind }
attributes #6 = { norecurse nounwind readnone }
attributes #7 = { nobuiltin nounwind }
attributes #8 = { noinline }

!llvm.module.flags = !{!0, !1, !2, !3, !4, !5, !6}
!llvm.ident = !{!7, !7, !7, !7, !7, !7}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 1}
!2 = !{i32 2, !"halide_use_soft_float_abi", i32 0}
!3 = !{i32 2, !"halide_mcpu", !"haswell"}
!4 = !{i32 2, !"halide_mattrs", !"+fma,+f16c"}
!5 = !{i32 2, !"halide_use_pic", i32 1}
!6 = !{i32 2, !"halide_per_instruction_fast_math_flags", i32 0}
!7 = !{!"clang version 9.0.1 (https://github.com/llvm/llvm-project.git c1a0a213378a458fbea1a5c77b315c7dce08fd05)"}
!8 = !{!"branch_weights", i32 0, i32 1073741824}
!9 = !{!10, !14, i64 16}
!10 = !{!"_ZTS15halide_buffer_t", !11, i64 0, !14, i64 8, !14, i64 16, !11, i64 24, !15, i64 32, !17, i64 36, !14, i64 40, !14, i64 48}
!11 = !{!"long long", !12, i64 0}
!12 = !{!"omnipotent char", !13, i64 0}
!13 = !{!"Simple C++ TBAA"}
!14 = !{!"any pointer", !12, i64 0}
!15 = !{!"_ZTS13halide_type_t", !12, i64 0, !12, i64 1, !16, i64 2}
!16 = !{!"short", !12, i64 0}
!17 = !{!"int", !12, i64 0}
!18 = !{!17, !17, i64 0}
!19 = !{!10, !11, i64 24}
!20 = !{!10, !17, i64 36}
!21 = !{!10, !14, i64 40}
!22 = !{!23, !17, i64 0}
!23 = !{!"_ZTS18halide_dimension_t", !17, i64 0, !17, i64 4, !17, i64 8, !17, i64 12}
!24 = !{!23, !17, i64 4}
!25 = !{!23, !17, i64 8}
!26 = !{!10, !11, i64 0}
!27 = !{!10, !12, i64 32}
!28 = !{!10, !12, i64 33}
!29 = !{!10, !16, i64 34}
!30 = !{i64 0, i64 4, !18, i64 4, i64 4, !18, i64 8, i64 4, !18, i64 12, i64 4, !18}
!31 = !{i64 0, i64 64}
!32 = !{!"branch_weights", i32 1073741824, i32 0, i32 0, i32 0, i32 0, i32 0}
!33 = !{!"branch_weights", i32 1073741824, i32 0}
!34 = !{!35, !35, i64 0}
!35 = !{!"gradient", !36, i64 0}
!36 = !{!"Halide buffer"}
!37 = distinct !{!37, !38}
!38 = !{!"llvm.loop.isvectorized", i32 1}
!39 = distinct !{!39, !40}
!40 = !{!"llvm.loop.unroll.disable"}
!41 = distinct !{!41, !42, !38}
!42 = !{!"llvm.loop.unroll.runtime.disable"}
Creating new execution engine
Target triple: x86_64--linux-gnu
JIT compiling shared runtime for x86-64-linux-avx-avx2-f16c-fma-jit-sse41-user_context
JIT Compiling halide_buffer_copy
Function halide_buffer_copy is at 0x7f7b7aa90f40
JIT Compiling halide_buffer_copy_already_locked
Function halide_buffer_copy_already_locked is at 0x7f7b7aa8f000
JIT Compiling halide_buffer_to_string
Function halide_buffer_to_string is at 0x7f7b7aa8f2f0
JIT Compiling halide_cache_cleanup
Function halide_cache_cleanup is at 0x7f7b7aa8f510
JIT Compiling halide_can_reuse_device_allocations
Function halide_can_reuse_device_allocations is at 0x7f7b7aa8f530
JIT Compiling halide_cond_broadcast
Function halide_cond_broadcast is at 0x7f7b7aa8f550
JIT Compiling halide_cond_signal
Function halide_cond_signal is at 0x7f7b7aa8f5c0
JIT Compiling halide_cond_wait
Function halide_cond_wait is at 0x7f7b7aa8f630
JIT Compiling halide_copy_to_device
Function halide_copy_to_device is at 0x7f7b7aa8f7c0
JIT Compiling halide_copy_to_host
Function halide_copy_to_host is at 0x7f7b7aa8f820
JIT Compiling halide_current_time_ns
Function halide_current_time_ns is at 0x7f7b7aa8f900
JIT Compiling halide_debug_to_file
Function halide_debug_to_file is at 0x7f7b7aa8e000
JIT Compiling halide_default_buffer_copy
Function halide_default_buffer_copy is at 0x7f7b7aa90fe0
JIT Compiling halide_default_device_and_host_free
Function halide_default_device_and_host_free is at 0x7f7b7aa8f950
JIT Compiling halide_default_device_and_host_malloc
Function halide_default_device_and_host_malloc is at 0x7f7b7aa8fa30
JIT Compiling halide_default_device_crop
Function halide_default_device_crop is at 0x7f7b7aa8fbf0
JIT Compiling halide_default_device_detach_native
Function halide_default_device_detach_native is at 0x7f7b7aa8fc20
JIT Compiling halide_default_device_release_crop
Function halide_default_device_release_crop is at 0x7f7b7aa8fce0
JIT Compiling halide_default_device_slice
Function halide_default_device_slice is at 0x7f7b7aa8fd10
JIT Compiling halide_default_device_wrap_native
Function halide_default_device_wrap_native is at 0x7f7b7aa8fd40
JIT Compiling halide_default_do_loop_task
Function halide_default_do_loop_task is at 0x7f7b7aa8fdf0
JIT Compiling halide_default_do_par_for
Function halide_default_do_par_for is at 0x7f7b7aa8fe10
JIT Compiling halide_default_do_parallel_tasks
Function halide_default_do_parallel_tasks is at 0x7f7b7aa8ec30
JIT Compiling halide_default_do_task
Function halide_default_do_task is at 0x7f7b7aa8fef0
JIT Compiling halide_default_error
Function halide_default_error is at 0x7f7b7aa8ff00
JIT Compiling halide_default_free
Function halide_default_free is at 0x7f7b7aa8ffb0
JIT Compiling halide_default_get_library_symbol
Function halide_default_get_library_symbol is at 0x7f7b7aa8ffd0
JIT Compiling halide_default_get_symbol
Function halide_default_get_symbol is at 0x7f7b7aa8ed60
JIT Compiling halide_default_load_library
Function halide_default_load_library is at 0x7f7b7aa8ed80
JIT Compiling halide_default_malloc
Function halide_default_malloc is at 0x7f7b7aa8edc0
JIT Compiling halide_default_print
Function halide_default_print is at 0x7f7b7aa8ee10
JIT Compiling halide_default_semaphore_init
Function halide_default_semaphore_init is at 0x7f7b7aa8ee50
JIT Compiling halide_default_semaphore_release
Function halide_default_semaphore_release is at 0x7f7b7aa8ee60
JIT Compiling halide_default_semaphore_try_acquire
Function halide_default_semaphore_try_acquire is at 0x7f7b7aa8eed0
JIT Compiling halide_default_trace
Function halide_default_trace is at 0x7f7b7aa8d000
JIT Compiling halide_device_and_host_free
Function halide_device_and_host_free is at 0x7f7b7aa8da40
JIT Compiling halide_device_and_host_free_as_destructor
Function halide_device_and_host_free_as_destructor is at 0x7f7b7aa8ef00
JIT Compiling halide_device_and_host_malloc
Function halide_device_and_host_malloc is at 0x7f7b7aa8db90
JIT Compiling halide_device_crop
Function halide_device_crop is at 0x7f7b7aa8ef20
JIT Compiling halide_device_detach_native
Function halide_device_detach_native is at 0x7f7b7aa8dcc0
JIT Compiling halide_device_free
Function halide_device_free is at 0x7f7b7aa8dde0
JIT Compiling halide_device_free_as_destructor
Function halide_device_free_as_destructor is at 0x7f7b7aa8df00
JIT Compiling halide_device_host_nop_free
Function halide_device_host_nop_free is at 0x7f7b7aa8efe0
JIT Compiling halide_device_malloc
Function halide_device_malloc is at 0x7f7b7aa8c000
JIT Compiling halide_device_release
Function halide_device_release is at 0x7f7b7aa8df20
JIT Compiling halide_device_release_crop
Function halide_device_release_crop is at 0x7f7b7aa8df30
JIT Compiling halide_device_slice
Function halide_device_slice is at 0x7f7b7aa8c110
JIT Compiling halide_device_sync
Function halide_device_sync is at 0x7f7b7aa8c1e0
JIT Compiling halide_device_wrap_native
Function halide_device_wrap_native is at 0x7f7b7aa8c2c0
JIT Compiling halide_do_loop_task
Function halide_do_loop_task is at 0x7f7b7aa8dfb0
JIT Compiling halide_do_par_for
Function halide_do_par_for is at 0x7f7b7aa8dfd0
JIT Compiling halide_do_parallel_tasks
Function halide_do_parallel_tasks is at 0x7f7b7aa8c3e0
JIT Compiling halide_do_task
Function halide_do_task is at 0x7f7b7aa8c400
JIT Compiling halide_double_to_string
Function halide_double_to_string is at 0x7f7b7aa8c420
JIT Compiling halide_error
Function halide_error is at 0x7f7b7aa8c930
JIT Compiling halide_error_access_out_of_bounds
Function halide_error_access_out_of_bounds is at 0x7f7b7aa8c950
JIT Compiling halide_error_bad_dimensions
Function halide_error_bad_dimensions is at 0x7f7b7aa8cc10
JIT Compiling halide_error_bad_extern_fold
Function halide_error_bad_extern_fold is at 0x7f7b7aa8b000
JIT Compiling halide_error_bad_fold
Function halide_error_bad_fold is at 0x7f7b7aa8cd70
JIT Compiling halide_error_bad_type
Function halide_error_bad_type is at 0x7f7b7aa8b3a0
JIT Compiling halide_error_bounds_inference_call_failed
Function halide_error_bounds_inference_call_failed is at 0x7f7b7aa8b520
JIT Compiling halide_error_buffer_allocation_too_large
Function halide_error_buffer_allocation_too_large is at 0x7f7b7aa8b650
JIT Compiling halide_error_buffer_argument_is_null
Function halide_error_buffer_argument_is_null is at 0x7f7b7aa8b7a0
JIT Compiling halide_error_buffer_extents_negative
Function halide_error_buffer_extents_negative is at 0x7f7b7aa8b8b0
JIT Compiling halide_error_buffer_extents_too_large
Function halide_error_buffer_extents_too_large is at 0x7f7b7aa8ba10
JIT Compiling halide_error_buffer_is_null
Function halide_error_buffer_is_null is at 0x7f7b7aa8bb60
JIT Compiling halide_error_constraint_violated
Function halide_error_constraint_violated is at 0x7f7b7aa8bc70
JIT Compiling halide_error_constraints_make_required_region_smaller
Function halide_error_constraints_make_required_region_smaller is at 0x7f7b7aa8a000
JIT Compiling halide_error_debug_to_file_failed
Function halide_error_debug_to_file_failed is at 0x7f7b7aa8be10
JIT Compiling halide_error_device_dirty_with_no_device_support
Function halide_error_device_dirty_with_no_device_support is at 0x7f7b7aa8a220
JIT Compiling halide_error_device_interface_no_device
Function halide_error_device_interface_no_device is at 0x7f7b7aa8cef0
JIT Compiling halide_error_explicit_bounds_too_small
Function halide_error_explicit_bounds_too_small is at 0x7f7b7aa8a340
JIT Compiling halide_error_extern_stage_failed
Function halide_error_extern_stage_failed is at 0x7f7b7aa8a530
JIT Compiling halide_error_fold_factor_too_small
Function halide_error_fold_factor_too_small is at 0x7f7b7aa8a660
JIT Compiling halide_error_host_and_device_dirty
Function halide_error_host_and_device_dirty is at 0x7f7b7aa8a840
JIT Compiling halide_error_host_is_null
Function halide_error_host_is_null is at 0x7f7b7aa8a910
JIT Compiling halide_error_no_device_interface
Function halide_error_no_device_interface is at 0x7f7b7aa8aa20
JIT Compiling halide_error_out_of_memory
Function halide_error_out_of_memory is at 0x7f7b7aa8cfc0
JIT Compiling halide_error_param_too_large_f64
Function halide_error_param_too_large_f64 is at 0x7f7b7aa8aaf0
JIT Compiling halide_error_param_too_large_i64
Function halide_error_param_too_large_i64 is at 0x7f7b7aa8ac50
JIT Compiling halide_error_param_too_large_u64
Function halide_error_param_too_large_u64 is at 0x7f7b7aa8ada0
JIT Compiling halide_error_param_too_small_f64
Function halide_error_param_too_small_f64 is at 0x7f7b7aa89000
JIT Compiling halide_error_param_too_small_i64
Function halide_error_param_too_small_i64 is at 0x7f7b7aa89160
JIT Compiling halide_error_param_too_small_u64
Function halide_error_param_too_small_u64 is at 0x7f7b7aa892b0
JIT Compiling halide_error_requirement_failed
Function halide_error_requirement_failed is at 0x7f7b7aa89400
JIT Compiling halide_error_specialize_fail
Function halide_error_specialize_fail is at 0x7f7b7aa8aef0
JIT Compiling halide_error_unaligned_host_ptr
Function halide_error_unaligned_host_ptr is at 0x7f7b7aa89530
JIT Compiling halide_float16_bits_to_double
Function halide_float16_bits_to_double is at 0x7f7b7aa8bf70
JIT Compiling halide_float16_bits_to_float
Function halide_float16_bits_to_float is at 0x7f7b7aa89670
JIT Compiling halide_free
Function halide_free is at 0x7f7b7aa8bf90
JIT Compiling halide_get_gpu_device
Function halide_get_gpu_device is at 0x7f7b7aa896e0
JIT Compiling halide_get_library_symbol
Function halide_get_library_symbol is at 0x7f7b7aa8bfb0
JIT Compiling halide_get_symbol
Function halide_get_symbol is at 0x7f7b7aa8bfd0
JIT Compiling halide_get_trace_file
Function halide_get_trace_file is at 0x7f7b7aa89780
JIT Compiling halide_host_cpu_count
Function halide_host_cpu_count is at 0x7f7b7aa898b0
JIT Compiling halide_int64_to_string
Function halide_int64_to_string is at 0x7f7b7aa898d0
JIT Compiling halide_join_thread
Function halide_join_thread is at 0x7f7b7aa89900
JIT Compiling halide_load_library
Function halide_load_library is at 0x7f7b7aa89940
JIT Compiling halide_malloc
Function halide_malloc is at 0x7f7b7aa89960
JIT Compiling halide_memoization_cache_cleanup
Function halide_memoization_cache_cleanup is at 0x7f7b7aa89980
JIT Compiling halide_memoization_cache_lookup
Function halide_memoization_cache_lookup is at 0x7f7b7aa89a40
JIT Compiling halide_memoization_cache_release
Function halide_memoization_cache_release is at 0x7f7b7aa89f30
JIT Compiling halide_memoization_cache_set_size
Function halide_memoization_cache_set_size is at 0x7f7b7aa88000
JIT Compiling halide_memoization_cache_store
Function halide_memoization_cache_store is at 0x7f7b7aa88060
JIT Compiling halide_msan_annotate_buffer_is_initialized
Function halide_msan_annotate_buffer_is_initialized is at 0x7f7b7aa89fd0
JIT Compiling halide_msan_annotate_buffer_is_initialized_as_destructor
Function halide_msan_annotate_buffer_is_initialized_as_destructor is at 0x7f7b7aa89fe0
JIT Compiling halide_msan_annotate_memory_is_initialized
Function halide_msan_annotate_memory_is_initialized is at 0x7f7b7aa88550
JIT Compiling halide_msan_check_buffer_is_initialized
Function halide_msan_check_buffer_is_initialized is at 0x7f7b7aa88560
JIT Compiling halide_msan_check_memory_is_initialized
Function halide_msan_check_memory_is_initialized is at 0x7f7b7aa88570
JIT Compiling halide_mutex_array_create
Function halide_mutex_array_create is at 0x7f7b7aa88580
JIT Compiling halide_mutex_array_destroy
Function halide_mutex_array_destroy is at 0x7f7b7aa88600
JIT Compiling halide_mutex_array_lock
Function halide_mutex_array_lock is at 0x7f7b7aa88640
JIT Compiling halide_mutex_array_unlock
Function halide_mutex_array_unlock is at 0x7f7b7aa88670
JIT Compiling halide_mutex_lock
Function halide_mutex_lock is at 0x7f7b7aa886a0
JIT Compiling halide_mutex_unlock
Function halide_mutex_unlock is at 0x7f7b7aa887c0
JIT Compiling halide_pointer_to_string
Function halide_pointer_to_string is at 0x7f7b7aa88840
JIT Compiling halide_print
Function halide_print is at 0x7f7b7aa888b0
JIT Compiling halide_profiler_get_pipeline_state
Function halide_profiler_get_pipeline_state is at 0x7f7b7aa888d0
JIT Compiling halide_profiler_get_state
Function halide_profiler_get_state is at 0x7f7b7aa88940
JIT Compiling halide_profiler_memory_allocate
Function halide_profiler_memory_allocate is at 0x7f7b7aa88950
JIT Compiling halide_profiler_memory_free
Function halide_profiler_memory_free is at 0x7f7b7aa88a90
JIT Compiling halide_profiler_pipeline_end
Function halide_profiler_pipeline_end is at 0x7f7b7aa88b60
JIT Compiling halide_profiler_pipeline_start
Function halide_profiler_pipeline_start is at 0x7f7b7aa88b70
JIT Compiling halide_profiler_report
Function halide_profiler_report is at 0x7f7b7aa88c30
JIT Compiling halide_profiler_report_unlocked
Function halide_profiler_report_unlocked is at 0x7f7b7aa87000
JIT Compiling halide_profiler_reset
Function halide_profiler_reset is at 0x7f7b7aa88c80
JIT Compiling halide_profiler_reset_unlocked
Function halide_profiler_reset_unlocked is at 0x7f7b7aa88cd0
JIT Compiling halide_profiler_shutdown
Function halide_profiler_shutdown is at 0x7f7b7aa88d30
JIT Compiling halide_profiler_stack_peak_update
Function halide_profiler_stack_peak_update is at 0x7f7b7aa88da0
JIT Compiling halide_register_device_allocation_pool
Function halide_register_device_allocation_pool is at 0x7f7b7aa88e50
JIT Compiling halide_reuse_device_allocations
Function halide_reuse_device_allocations is at 0x7f7b7aa88ea0
JIT Compiling halide_semaphore_init
Function halide_semaphore_init is at 0x7f7b7aa88f30
JIT Compiling halide_semaphore_release
Function halide_semaphore_release is at 0x7f7b7aa88f50
JIT Compiling halide_semaphore_try_acquire
Function halide_semaphore_try_acquire is at 0x7f7b7aa88f70
JIT Compiling halide_set_custom_do_loop_task
Function halide_set_custom_do_loop_task is at 0x7f7b7aa88f90
JIT Compiling halide_set_custom_do_par_for
Function halide_set_custom_do_par_for is at 0x7f7b7aa88fb0
JIT Compiling halide_set_custom_do_task
Function halide_set_custom_do_task is at 0x7f7b7aa88fd0
JIT Compiling halide_set_custom_free
Function halide_set_custom_free is at 0x7f7b7aa87930
JIT Compiling halide_set_custom_get_library_symbol
Function halide_set_custom_get_library_symbol is at 0x7f7b7aa87950
JIT Compiling halide_set_custom_get_symbol
Function halide_set_custom_get_symbol is at 0x7f7b7aa87970
JIT Compiling halide_set_custom_load_library
Function halide_set_custom_load_library is at 0x7f7b7aa87990
JIT Compiling halide_set_custom_malloc
Function halide_set_custom_malloc is at 0x7f7b7aa879b0
JIT Compiling halide_set_custom_parallel_runtime
Function halide_set_custom_parallel_runtime is at 0x7f7b7aa879d0
JIT Compiling halide_set_custom_print
Function halide_set_custom_print is at 0x7f7b7aa87a40
JIT Compiling halide_set_custom_trace
Function halide_set_custom_trace is at 0x7f7b7aa87a60
JIT Compiling halide_set_error_handler
Function halide_set_error_handler is at 0x7f7b7aa87a80
JIT Compiling halide_set_gpu_device
Function halide_set_gpu_device is at 0x7f7b7aa87aa0
JIT Compiling halide_set_num_threads
Function halide_set_num_threads is at 0x7f7b7aa87ac0
JIT Compiling halide_set_trace_file
Function halide_set_trace_file is at 0x7f7b7aa87b70
JIT Compiling halide_shutdown_thread_pool
Function halide_shutdown_thread_pool is at 0x7f7b7aa87b90
JIT Compiling halide_shutdown_trace
Function halide_shutdown_trace is at 0x7f7b7aa87c60
JIT Compiling halide_sleep_ms
Function halide_sleep_ms is at 0x7f7b7aa87ce0
JIT Compiling halide_spawn_thread
Function halide_spawn_thread is at 0x7f7b7aa87d00
JIT Compiling halide_start_clock
Function halide_start_clock is at 0x7f7b7aa87d60
JIT Compiling halide_string_to_string
Function halide_string_to_string is at 0x7f7b7aa87da0
JIT Compiling halide_thread_pool_cleanup
Function halide_thread_pool_cleanup is at 0x7f7b7aa87dd0
JIT Compiling halide_trace
Function halide_trace is at 0x7f7b7aa87df0
JIT Compiling halide_trace_cleanup
Function halide_trace_cleanup is at 0x7f7b7aa87e10
JIT Compiling halide_trace_helper
Function halide_trace_helper is at 0x7f7b7aa87e30
JIT Compiling halide_type_to_string
Function halide_type_to_string is at 0x7f7b7aa87f00
JIT Compiling halide_uint64_to_string
Function halide_uint64_to_string is at 0x7f7b7aa86000
Finalizing object
Creating new execution engine
Target triple: x86_64--linux-gnu
JIT compiling gradient for x86-64-linux-avx-avx2-f16c-fma-jit-sse41-user_context
JIT Compiling gradient
Function gradient is at 0x7f7b7aa83000
JIT Compiling gradient_argv
Function gradient_argv is at 0x7f7b7aa83620
Finalizing object
custom_print: 0x7f7b7aa8ee10
custom_malloc: 0x7f7b7aa8edc0
custom_free: 0x7f7b7aa8ffb0
custom_do_task: 0x7f7b7aa8fef0
custom_do_par_for: 0x7f7b7aa8fe10
custom_error: 0x7f7b755e4270
custom_trace: 0x7f7b7aa8d000
__user_context @ 0x7ffdd4970a48
JIT output buffer @ 0x1c55cd8, 0
Calling jitted function
Back from jitted function. Exit status was 0
Realizing Pipeline for target(arch_unknown-0-os_unknown)
jit-compiling for: target(x86-64-linux-avx-avx2-f16c-fma-jit-sse41-user_context)
Reusing old jit module compiled for :
target(x86-64-linux-avx-avx2-f16c-fma-jit-sse41-user_context)
custom_print: 0x7f7b7aa8ee10
custom_malloc: 0x7f7b7aa8edc0
custom_free: 0x7f7b7aa8ffb0
custom_do_task: 0x7f7b7aa8fef0
custom_do_par_for: 0x7f7b7aa8fe10
custom_error: 0x7f7b755e4270
custom_trace: 0x7f7b7aa8d000
__user_context @ 0x7ffdd4970a48
JIT output buffer @ 0x1c55cd8, 0x1eddd80
Calling jitted function
Back from jitted function. Exit status was 0
Creating initial loop nests...
Injecting realization of { gradient }
for (.__root, 0, 1) {
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  let gradient.s0.__outermost.loop_extent = 1
  let gradient.s0.__outermost.loop_max = 0
  let gradient.s0.__outermost.loop_min = 0
  for (gradient.s0.__outermost, gradient.s0.__outermost.loop_min, gradient.s0.__outermost.loop_extent) {
   for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
    for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
     gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
    }
   }
  }
 }
}

Lowering after creating initial loop nests:
produce gradient {
 let gradient.s0.y.loop_max = gradient.s0.y.max
 let gradient.s0.y.loop_min = gradient.s0.y.min
 let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
 let gradient.s0.x.loop_max = gradient.s0.x.max
 let gradient.s0.x.loop_min = gradient.s0.x.min
 let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
 for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
  for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
   gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
  }
 }
}

Skipping injecting memoization...
Injecting tracing...
Lowering after injecting tracing:
produce gradient {
 let gradient.s0.y.loop_max = gradient.s0.y.max
 let gradient.s0.y.loop_min = gradient.s0.y.min
 let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
 let gradient.s0.x.loop_max = gradient.s0.x.max
 let gradient.s0.x.loop_min = gradient.s0.x.min
 let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
 for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
  for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
   gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
  }
 }
}

Adding checks for parameters
Lowering after injecting parameter checks:
produce gradient {
 let gradient.s0.y.loop_max = gradient.s0.y.max
 let gradient.s0.y.loop_min = gradient.s0.y.min
 let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
 let gradient.s0.x.loop_max = gradient.s0.x.max
 let gradient.s0.x.loop_min = gradient.s0.x.min
 let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
 for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
  for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
   gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
  }
 }
}

Computing bounds of each function's value
Bounds on value 0 for func gradient are: ((void *))neg_inf, ((void *))pos_inf
Adding checks for images
Injecting constraints for gradient.0
Injecting constraints for gradient.1
Lowering after injecting image checks:
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Performing computation bounds inference...
Lowering after computation bounds inference:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Removing extern loops...
Lowering after removing extern loops:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Performing sliding window optimization...
Lowering after sliding window:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Simplifying correlated differences...
Lowering after simplifying correlated differences:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Performing allocation bounds inference...
Lowering after allocation bounds inference:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Removing code that depends on undef values...
Lowering after removing code that depends on undef values:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Uniquifying variable names...
Lowering after uniquifying variable names:
let gradient.s0.y.max = ((gradient.min.1 + gradient.extent.1) - 1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.min.0 + gradient.extent.0) - 1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
let gradient.min.0.required = gradient.s0.x.min
let gradient.stride.0.required = 1
let gradient.extent.1.required = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
let gradient.min.1.required = gradient.s0.y.min
let gradient.stride.1.required = (gradient.stride.0.required*gradient.extent.0.required)
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0.required
let gradient.extent.0.proposed = gradient.extent.0.required
let gradient.stride.1.proposed = gradient.stride.1.required
let gradient.min.1.proposed = gradient.min.1.required
let gradient.extent.1.proposed = gradient.extent.1.required
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.0.proposed <= gradient.min.0.required) && (((gradient.min.0.proposed + gradient.extent.0.proposed) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 0, gradient.min.0.proposed, ((gradient.min.0.proposed + gradient.extent.0.proposed) - 1), gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1)))
assert((!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer) || ((gradient.min.1.proposed <= gradient.min.1.required) && (((gradient.min.1.proposed + gradient.extent.1.proposed) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1)))), halide_error_constraints_make_required_region_smaller("Output buffer gradient", 1, gradient.min.1.proposed, ((gradient.min.1.proposed + gradient.extent.1.proposed) - 1), gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1)))
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0.proposed, gradient.extent.0.proposed, gradient.stride.0.proposed, 0, gradient.min.1.proposed, gradient.extent.1.proposed, gradient.stride.1.proposed, 0), (uint64)0)
}
if (!((uint1)0 || (uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer))) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert(((gradient.min.0 <= gradient.min.0.required) && (((gradient.min.0 + gradient.extent.0) - 1) >= ((gradient.min.0.required + gradient.extent.0.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 0, gradient.min.0.required, ((gradient.min.0.required + gradient.extent.0.required) - 1), gradient.min.0, ((gradient.min.0 + gradient.extent.0) - 1)))
 assert((gradient.extent.0 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert(((gradient.min.1 <= gradient.min.1.required) && (((gradient.min.1 + gradient.extent.1) - 1) >= ((gradient.min.1.required + gradient.extent.1.required) - 1))), halide_error_access_out_of_bounds("Output buffer gradient", 1, gradient.min.1.required, ((gradient.min.1.required + gradient.extent.1.required) - 1), gradient.min.1, ((gradient.min.1 + gradient.extent.1) - 1)))
 assert((gradient.extent.1 >= 0), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == gradient.stride.0.constrained), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", gradient.stride.0.constrained))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*gradient.total_extent.0)
 assert(((uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.0)*int64(gradient.stride.0.constrained))), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = gradient.s0.y.max
  let gradient.s0.y.loop_min = gradient.s0.y.min
  let gradient.s0.y.loop_extent = ((gradient.s0.y.max + 1) - gradient.s0.y.min)
  let gradient.s0.x.loop_max = gradient.s0.x.max
  let gradient.s0.x.loop_min = gradient.s0.x.min
  let gradient.s0.x.loop_extent = ((gradient.s0.x.max + 1) - gradient.s0.x.min)
  for (gradient.s0.y, gradient.s0.y.loop_min, gradient.s0.y.loop_extent) {
   for (gradient.s0.x, gradient.s0.x.loop_min, gradient.s0.x.loop_extent) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Simplifying...
Lowering after first simplification:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Performing storage folding optimization...
Lowering after storage folding:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Injecting debug_to_file calls...
Lowering after injecting debug_to_file calls:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Injecting prefetches...
Lowering after injecting prefetches:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Discarding safe promises...
Lowering after discarding safe promises:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Dynamically skipping stages...
Lowering after dynamically skipping stages:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
  let gradient.s0.y.loop_min = gradient.min.1
  let gradient.s0.y.loop_extent = gradient.extent.1
  let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
  let gradient.s0.x.loop_min = gradient.min.0
  let gradient.s0.x.loop_extent = gradient.extent.0
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Forking asynchronous producers...
Lowering after forking asynchronous producers:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Destructuring tuple-valued realizations...
Lowering after destructuring tuple-valued realizations:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient(gradient.s0.x, gradient.s0.y) = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Performing storage flattening...
Lowering after storage flattening:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((0 + (gradient.s0.x*gradient.stride.0)) + (gradient.s0.y*gradient.stride.1)) - ((0 + (gradient.min.0*gradient.stride.0)) + (gradient.min.1*gradient.stride.1)))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Adding atomic mutex allocation...
Lowering after adding atomic mutex allocation:
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert(((uint32)gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", (uint32)gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!(uint1)gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((((void *))gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((0 + (gradient.s0.x*gradient.stride.0)) + (gradient.s0.y*gradient.stride.1)) - ((0 + (gradient.min.0*gradient.stride.0)) + (gradient.min.1*gradient.stride.1)))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Unpacking buffer arguments...
Lowering after unpacking buffer arguments...
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
let gradient.s0.y.max = ((gradient.extent.1 + gradient.min.1) + -1)
let gradient.s0.y.min = gradient.min.1
let gradient.s0.x.max = ((gradient.extent.0 + gradient.min.0) + -1)
let gradient.s0.x.min = gradient.min.0
let gradient.extent.0.required = gradient.extent.0
let gradient.min.0.required = gradient.min.0
let gradient.stride.0.required = 1
let gradient.extent.1.required = gradient.extent.1
let gradient.min.1.required = gradient.min.1
let gradient.stride.1.required = gradient.extent.0
let gradient.stride.0.constrained = 1
let gradient.stride.0.proposed = 1
let gradient.min.0.proposed = gradient.min.0
let gradient.extent.0.proposed = gradient.extent.0
let gradient.stride.1.proposed = gradient.extent.0
let gradient.min.1.proposed = gradient.min.1
let gradient.extent.1.proposed = gradient.extent.1
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 0
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 0
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.0 = int64(gradient.extent.0)
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 let gradient.s0.y.loop_max = ((gradient.extent.1 + gradient.min.1) + -1)
 let gradient.s0.y.loop_min = gradient.min.1
 let gradient.s0.y.loop_extent = gradient.extent.1
 let gradient.s0.x.loop_max = ((gradient.extent.0 + gradient.min.0) + -1)
 let gradient.s0.x.loop_min = gradient.min.0
 let gradient.s0.x.loop_extent = gradient.extent.0
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((0 + (gradient.s0.x*gradient.stride.0)) + (gradient.s0.y*gradient.stride.1)) - ((0 + (gradient.min.0*gradient.stride.0)) + (gradient.min.1*gradient.stride.1)))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Skipping rewriting memoized allocations...
Simplifying...
Lowering after second simplifcation:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Reduce prefetch dimension...
Lowering after reduce prefetch dimension:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Simplifying correlated differences...
Lowering after simplifying correlated differences:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Unrolling...
Lowering after unrolling:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Vectorizing...
Lowering after vectorizing:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Detecting vector interleavings...
Lowering after rewriting vector interleavings:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Partitioning loops to simplify boundary conditions...
Lowering after partitioning loops:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Trimming loops to the region over which they do something...
Lowering after loop trimming:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Injecting early frees...
Lowering after injecting early frees:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Simplifying correlated differences...
Lowering after simplifying correlated differences:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}

Bounding small allocations...
Lowering after bounding small allocations:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Simplifying...
Lowering unsafe promises...
Lowering after lowering unsafe promises:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(((gradient.s0.y*gradient.stride.1) + gradient.s0.x) - ((gradient.min.1*gradient.stride.1) + gradient.min.0))] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Lowering after final simplification:
assert(((uint64)reinterpret(((halide_buffer_t *))gradient.buffer) != (uint64)0), halide_error_buffer_argument_is_null("gradient"))
let gradient = ((void *))_halide_buffer_get_host(((halide_buffer_t *))gradient.buffer)
let gradient.type = (uint32)_halide_buffer_get_type(((halide_buffer_t *))gradient.buffer)
let gradient.device_dirty = (uint1)_halide_buffer_get_device_dirty(((halide_buffer_t *))gradient.buffer)
let gradient.dimensions = _halide_buffer_get_dimensions(((halide_buffer_t *))gradient.buffer)
let gradient.min.0 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 0)
let gradient.extent.0 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 0)
let gradient.stride.0 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 0)
let gradient.min.1 = _halide_buffer_get_min(((halide_buffer_t *))gradient.buffer, 1)
let gradient.extent.1 = _halide_buffer_get_extent(((halide_buffer_t *))gradient.buffer, 1)
let gradient.stride.1 = _halide_buffer_get_stride(((halide_buffer_t *))gradient.buffer, 1)
if ((uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 ((halide_buffer_t *))_halide_buffer_init(((halide_buffer_t *))gradient.buffer, ((halide_dimension_t *))_halide_buffer_get_shape(((halide_buffer_t *))gradient.buffer), ((void *))reinterpret((uint64)0), (uint64)0, ((halide_device_interface_t *))reinterpret((uint64)0), 0, 32, 2, ((halide_dimension_t *))make_struct(gradient.min.0, gradient.extent.0, 1, 0, gradient.min.1, gradient.extent.1, gradient.extent.0, 0), (uint64)0)
}
if (!(uint1)_halide_buffer_is_bounds_query(((halide_buffer_t *))gradient.buffer)) {
 assert((gradient.type == (uint32)73728), halide_error_bad_type("Output buffer gradient", gradient.type, (uint32)73728))
 assert((gradient.dimensions == 2), halide_error_bad_dimensions("Output buffer gradient", gradient.dimensions, 2))
 assert((0 <= gradient.extent.0), halide_error_buffer_extents_negative("Output buffer gradient", 0, gradient.extent.0))
 assert((0 <= gradient.extent.1), halide_error_buffer_extents_negative("Output buffer gradient", 1, gradient.extent.1))
 assert((gradient.stride.0 == 1), halide_error_constraint_violated("gradient.stride.0", gradient.stride.0, "1", 1))
 let gradient.total_extent.1 = (int64(gradient.extent.1)*int64(gradient.extent.0))
 assert(((uint64)abs(int64(gradient.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs(int64(gradient.extent.0)), (uint64)2147483647))
 assert(((uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("gradient", (uint64)abs((int64(gradient.extent.1)*int64(gradient.stride.1))), (uint64)2147483647))
 assert((gradient.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("gradient", gradient.total_extent.1, (int64)2147483647))
 assert(!gradient.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer gradient"))
 assert((gradient != ((void *))reinterpret((uint64)0)), halide_error_host_is_null("Output buffer gradient"))
 produce gradient {
  let t4 = ((gradient.min.1*gradient.stride.1) + gradient.min.0)
  for (gradient.s0.y, gradient.min.1, gradient.extent.1) {
   let t5 = ((gradient.s0.y*gradient.stride.1) - t4)
   for (gradient.s0.x, gradient.min.0, gradient.extent.0) {
    gradient[(gradient.s0.x + t5)] = (gradient.s0.x + gradient.s0.y)
   }
  }
 }
}


Skipping Hexagon offload...
Module.compile(): stmt_html gradient.html
Success!
